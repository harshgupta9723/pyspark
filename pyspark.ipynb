{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Z_WjhhtCFIWP"
      ],
      "mount_file_id": "1emMgDZzf31KGk6AMn80M9iscBP7KrOte",
      "authorship_tag": "ABX9TyO6DW+5ydIx33AjbuzzBmFA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshgupta9723/pyspark/blob/main/pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StZQqxUAAqWD"
      },
      "source": [
        "# **CONFIGURING PYSPARK**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTIl7IhlAbm2"
      },
      "source": [
        "* Download Java."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycK-VZNR3feL"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ovbTUYAof5"
      },
      "source": [
        "\n",
        "\n",
        "*   Installing Apache Spark 3.0.1 with Hadoop 2.7 - \n",
        "check updated version [here](https://spark.apache.org/downloads.html)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkttprCf9Ela"
      },
      "source": [
        "!wget -q  https://mirrors.estointernet.in/apache/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owPiS0ImBenE"
      },
      "source": [
        "\n",
        "\n",
        "*    Unziping\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwaiStKO9GlF"
      },
      "source": [
        "!tar xf /content/spark-3.1.1-bin-hadoop2.7.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJd_6546BkqW"
      },
      "source": [
        "\n",
        "\n",
        "*    Install findspark library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcC0IyIX3ffi"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNTDUDyDBuC0"
      },
      "source": [
        "\n",
        "\n",
        "*    Setting the environment path.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwlKjUqo3fig"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TutLtqIB7nC"
      },
      "source": [
        "\n",
        "\n",
        "*   Import findspark and use the findspark.init() method.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqKtY3go3fj9"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rssmlzPCKKI"
      },
      "source": [
        "\n",
        "\n",
        "*   Location where Spark is installed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wL_HVmLl3fny",
        "outputId": "63e6901d-1858-47da-b39e-1450460fc6d9"
      },
      "source": [
        "findspark.find()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-3.1.1-bin-hadoop2.7'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSGWwQaACOJe"
      },
      "source": [
        "\n",
        "\n",
        "*    Import SparkSession from pyspark.sql and create a SparkSession\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGpmvqHB-X91"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ihysl29Ccj9"
      },
      "source": [
        "\n",
        "\n",
        "*    Import SparkSession from pyspark.sql and create a SparkSession."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "tZpGxZ0b-fli",
        "outputId": "924319d1-9ab3-4873-f459-845ae8409a4d"
      },
      "source": [
        "spark"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6760135a1138:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f6256adc190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UKLP-m9H1Ta"
      },
      "source": [
        "\n",
        "\n",
        "*   Install pyspark\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRBgdWDJ-quE"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZeX-XjTIbmf"
      },
      "source": [
        "# First pyspark job"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiGp_3VFInuo"
      },
      "source": [
        "import pyspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFoh0UKBI9ET"
      },
      "source": [
        "# creating a spark context\n",
        "\n",
        "from pyspark import SparkConf\n",
        "from pyspark import SparkContext\n",
        "conf = SparkConf()\n",
        "conf.setMaster('local')\n",
        "conf.setAppName('spark-basic')\n",
        "sc = SparkContext(conf=conf)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuhAPSHwI9Fj"
      },
      "source": [
        "# Function to calculate mod\n",
        "\n",
        "def mod(x):\n",
        "    import numpy as np\n",
        "    return (x, np.mod(x, 2))\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJO4-x0sI9Jy",
        "outputId": "5f4c5b03-f3fa-4b47-d997-63f2aaf98b45"
      },
      "source": [
        "# Creating an RDD\n",
        "\n",
        "rdd = sc.parallelize(range(1000)).map(mod).take(10)\n",
        "print(rdd)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0), (1, 1), (2, 0), (3, 1), (4, 0), (5, 1), (6, 0), (7, 1), (8, 0), (9, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9W4gJIjI9V1"
      },
      "source": [
        "# Creating an rdd using list\n",
        "values = [1, 2, 3, 4, 5]\n",
        "rdd = sc.parallelize(values)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK9sfg2TI9Xb",
        "outputId": "32b56553-6594-4eec-babe-09cef9c204ad"
      },
      "source": [
        "# Printing all the 5 elements \n",
        "rdd.take(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCYfOthBI9bQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}