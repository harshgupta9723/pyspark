{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3n67IHvX16v2LPOCqYHMB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshgupta9723/pyspark/blob/main/pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5JM0QAZIR-i",
        "outputId": "6d3f01ca-5a34-4b8d-afd0-9cc27bbcc9ae"
      },
      "source": [
        "!java -version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ8fna_OI0ES"
      },
      "source": [
        "  Downloading spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUb6c5UKIw8y"
      },
      "source": [
        "!wget -q http://apachemirror.wuchna.com/spark/spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZVUM1E8LWOz"
      },
      "source": [
        "Extracting spark files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4UXM61RLVXd",
        "outputId": "b90124a2-4e7e-41b8-9833-508f1c921207"
      },
      "source": [
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar: spark-2.4.4-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLq_L0y_L73V"
      },
      "source": [
        "Installing find spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqg1X6MPL7IC"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz-bIKloO-Hq"
      },
      "source": [
        "Setting up home environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsfLm9svPCKs"
      },
      "source": [
        "import os\n",
        "os.environ[\"java home\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"spark home\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWDQ0MceQD3T"
      },
      "source": [
        "Creating spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqqOMEKCQGaK"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3-DQQgCEcjY"
      },
      "source": [
        "from pyspark import SparkConf\n",
        "from pyspark import SparkContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmLlHzhvEvs3"
      },
      "source": [
        "conf = SparkConf()\n",
        "conf.setMaster('local')\n",
        "conf.setAppName('spark-basic')\n",
        "sc = SparkContext(conf=conf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWtS5VJ9F82q"
      },
      "source": [
        "def mod(x):\n",
        "    import numpay as np\n",
        "    return (x, np.mod(x, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0ERs7GyGMmo"
      },
      "source": [
        "rdd = sc.parallelize(range(1000)).mop(mod).take(10)\n",
        "rdd"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}